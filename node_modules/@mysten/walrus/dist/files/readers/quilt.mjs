import { QuiltIndexV1, QuiltPatchBlobHeader, QuiltPatchId, QuiltPatchTags } from "../../utils/bcs.mjs";
import { urlSafeBase64 } from "../../utils/index.mjs";
import { HAS_TAGS_FLAG, QUILT_PATCH_BLOB_HEADER_SIZE, parseQuiltPatchId } from "../../utils/quilts.mjs";
import { QuiltFileReader } from "./quilt-file.mjs";
import { bcs } from "@mysten/bcs";
import { ClientCache } from "@mysten/sui/client";

//#region src/files/readers/quilt.ts
var QuiltReader = class {
	#blob;
	#cache = new ClientCache();
	constructor({ blob }) {
		this.#blob = blob;
	}
	async #readBytesFromSlivers(sliver, length, offset = 0, columnSize) {
		if (!length) return new Uint8Array(0);
		this.#blob.getSecondarySliver({ sliverIndex: sliver }).catch(() => {});
		columnSize = columnSize ?? await this.#blob.getColumnSize();
		const columnOffset = Math.floor(offset / columnSize);
		let remainingOffset = offset % columnSize;
		const bytes = new Uint8Array(length);
		let bytesRead = 0;
		const nSlivers = Math.ceil(length / columnSize);
		const slivers = new Array(nSlivers).fill(0).map((_, i) => this.#blob.getSecondarySliver({ sliverIndex: sliver + columnOffset + i }));
		slivers.forEach((p) => p.catch(() => {}));
		for (const sliverPromise of slivers) {
			const sliver$1 = await sliverPromise;
			let chunk = remainingOffset > 0 ? sliver$1.subarray(remainingOffset) : sliver$1;
			remainingOffset -= chunk.length;
			if (chunk.length > length - bytesRead) chunk = chunk.subarray(0, length - bytesRead);
			bytes.set(chunk, bytesRead);
			bytesRead += chunk.length;
			if (bytesRead >= length) break;
		}
		return bytes;
	}
	async #readBytesFromBlob(startColumn, length, offset = 0) {
		const result = new Uint8Array(length);
		if (!length) return result;
		const blob = await this.#blob.getBytes();
		const [rowSize, symbolSize] = await Promise.all([this.#blob.getRowSize(), this.#blob.getSymbolSize()]);
		const nRows = blob.length / rowSize;
		const symbolsToSkip = Math.floor(offset / symbolSize);
		let remainingOffset = offset % symbolSize;
		let currentCol = startColumn + Math.floor(symbolsToSkip / nRows);
		let currentRow = symbolsToSkip % nRows;
		let bytesRead = 0;
		while (bytesRead < length) {
			const baseIndex = currentRow * rowSize + currentCol * symbolSize;
			const startIndex = baseIndex + remainingOffset;
			const endIndex = Math.min(baseIndex + symbolSize, startIndex + length - bytesRead, blob.length);
			if (startIndex >= blob.length) throw new Error("Index out of bounds");
			const size = endIndex - startIndex;
			for (let i = 0; i < size; i++) result[bytesRead + i] = blob[startIndex + i];
			bytesRead += size;
			remainingOffset = 0;
			currentRow = (currentRow + 1) % nRows;
			if (currentRow === 0) currentCol += 1;
		}
		return result;
	}
	async #readBytes(sliver, length, offset = 0, columnSize) {
		if (this.#blob.hasStartedLoadingFullBlob) return this.#readBytesFromBlob(sliver, length, offset);
		try {
			return await this.#readBytesFromSlivers(sliver, length, offset, columnSize);
		} catch {
			return this.#readBytesFromBlob(sliver, length, offset);
		}
	}
	async getBlobHeader(sliverIndex) {
		return this.#cache.read(["getBlobHeader", sliverIndex.toString()], async () => {
			const blobHeader = QuiltPatchBlobHeader.parse(await this.#readBytes(sliverIndex, QUILT_PATCH_BLOB_HEADER_SIZE));
			let offset = QUILT_PATCH_BLOB_HEADER_SIZE;
			let blobSize = blobHeader.length;
			const identifierLength = new DataView((await this.#readBytes(sliverIndex, 2, offset)).buffer).getUint16(0, true);
			blobSize -= 2 + identifierLength;
			offset += 2;
			const identifier = bcs.string().parse(await this.#readBytes(sliverIndex, identifierLength, offset));
			offset += identifierLength;
			let tags = null;
			if (blobHeader.mask & HAS_TAGS_FLAG) {
				const tagsSize = new DataView((await this.#readBytes(sliverIndex, 2, offset)).buffer).getUint16(0, true);
				offset += 2;
				tags = QuiltPatchTags.parse(await this.#readBytes(sliverIndex, tagsSize, offset));
				blobSize -= tagsSize + 2;
				offset += tagsSize;
			}
			return {
				identifier,
				tags,
				blobSize,
				contentOffset: offset
			};
		});
	}
	async readBlob(sliverIndex) {
		const { identifier, tags, blobSize, contentOffset } = await this.getBlobHeader(sliverIndex);
		return {
			identifier,
			tags,
			blobContents: await this.#readBytes(sliverIndex, blobSize, contentOffset)
		};
	}
	readerForPatchId(id) {
		const { quiltId, patchId } = parseQuiltPatchId(id);
		if (quiltId !== this.#blob.blobId) throw new Error(`The requested patch ${patchId} is not part of the quilt ${this.#blob.blobId}`);
		return new QuiltFileReader({
			quilt: this,
			sliverIndex: patchId.startIndex
		});
	}
	async readIndex() {
		const header = new DataView((await this.#readBytes(0, 5)).buffer);
		const version = header.getUint8(0);
		if (version !== 1) throw new Error(`Unsupported quilt version ${version}`);
		const indexSize = header.getUint32(1, true);
		const indexBytes = await this.#readBytes(0, indexSize, 5);
		const columnSize = await this.#blob.getColumnSize();
		const indexSlivers = Math.ceil(indexSize / columnSize);
		const index = QuiltIndexV1.parse(indexBytes);
		return index.patches.map((patch, i) => {
			const startIndex = i === 0 ? indexSlivers : index.patches[i - 1].endIndex;
			const reader = new QuiltFileReader({
				quilt: this,
				sliverIndex: startIndex,
				identifier: patch.identifier,
				tags: patch.tags
			});
			return {
				identifier: patch.identifier,
				patchId: urlSafeBase64(QuiltPatchId.serialize({
					quiltId: this.#blob.blobId,
					patchId: {
						version: 1,
						startIndex,
						endIndex: patch.endIndex
					}
				}).toBytes()),
				tags: patch.tags,
				reader
			};
		});
	}
};

//#endregion
export { QuiltReader };
//# sourceMappingURL=quilt.mjs.map